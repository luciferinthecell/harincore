"""
harin.cli.memory_cli
~~~~~~~~~~~~~~~~~~~

ë©”ëª¨ë¦¬ ê´€ë¦¬ CLI ë„êµ¬
- í…ìŠ¤íŠ¸ íŒŒì¼ ì„í¬íŠ¸
- ê¸°ì–µ ê²€ìƒ‰
- ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
- ê¸°ì–µ íŒŒì¼ ê´€ë¦¬
"""

from __future__ import annotations

import json
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
import argparse

from memory.palantirgraph import PalantirGraph, initialize_memory
from memory.conscious_reader import ConsciousReader
from memory.memory_retriever import MemoryRetriever
from memory.text_importer import TextImporter


def cmd_import(args: argparse.Namespace):
    """í…ìŠ¤íŠ¸ íŒŒì¼ì„ ê¸°ì–µìœ¼ë¡œ ì„í¬íŠ¸"""
    print(f"ğŸ“– í…ìŠ¤íŠ¸ íŒŒì¼ ì„í¬íŠ¸: {args.file}")
    
    # ë©”ëª¨ë¦¬ ê·¸ë˜í”„ ì´ˆê¸°í™”
    graph = PalantirGraph("memory/data/palantir_graph.json")
    
    # í…ìŠ¤íŠ¸ ì„í¬í„° ìƒì„±
    importer = TextImporter(graph)
    
    # íŒŒì¼ ì„í¬íŠ¸
    result = importer.import_text_file(args.file, args.topic)
    
    print(f"âœ… ì„í¬íŠ¸ ì™„ë£Œ:")
    print(f"   - ì„¸ì…˜ ID: {result.session_id}")
    print(f"   - ì œëª©: {result.title}")
    print(f"   - ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(result.segments)}ê°œ")
    print(f"   - ì „ì²´ ì£¼ì œ: {', '.join(result.overall_topics)}")
    
    # ë©”ëª¨ë¦¬ ì €ì¥
    graph.save()
    print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì €ì¥ë¨: {graph.persist_path}")


def cmd_search(args: argparse.Namespace):
    """ê¸°ì–µ ê²€ìƒ‰"""
    print(f"ğŸ” ê¸°ì–µ ê²€ìƒ‰: {args.query}")
    
    # ë©”ëª¨ë¦¬ ê·¸ë˜í”„ ë¡œë“œ
    graph = PalantirGraph("memory/data/palantir_graph.json")
    
    # ë©”ëª¨ë¦¬ ê²€ìƒ‰ê¸° ìƒì„±
    retriever = MemoryRetriever(graph)
    
    # ê²€ìƒ‰ ì‹¤í–‰
    memories = retriever.retrieve_for_thinking(args.query)
    
    print(f"ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼ ({len(memories)}ê°œ):")
    for i, memory in enumerate(memories, 1):
        print(f"\n{i}. {memory.retrieval_reason} (ê´€ë ¨ë„: {memory.relevance_score:.2f})")
        print(f"   ë‚´ìš©: {memory.node.content[:100]}...")
        if memory.node.meta.get("topic"):
            print(f"   ì£¼ì œ: {memory.node.meta['topic']}")


def cmd_status(args: argparse.Namespace):
    """ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸"""
    print("ğŸ“Š ë©”ëª¨ë¦¬ ìƒíƒœ")
    
    # ë©”ëª¨ë¦¬ ê·¸ë˜í”„ ë¡œë“œ
    graph = PalantirGraph("memory/data/palantir_graph.json")
    
    print(f"ğŸ“ˆ ë…¸ë“œ ìˆ˜: {len(graph.nodes)}ê°œ")
    print(f"ğŸ”— ê´€ê³„ ìˆ˜: {len(graph.edges)}ê°œ")
    
    # ë…¸ë“œ íƒ€ì…ë³„ í†µê³„
    node_types = {}
    for node in graph.nodes.values():
        node_type = node.node_type
        node_types[node_type] = node_types.get(node_type, 0) + 1
    
    print("\nğŸ“‹ ë…¸ë“œ íƒ€ì…ë³„ í†µê³„:")
    for node_type, count in node_types.items():
        print(f"   {node_type}: {count}ê°œ")
    
    # ì£¼ì œë³„ í†µê³„
    topics = {}
    for node in graph.nodes.values():
        topic = node.meta.get("topic", "ê¸°íƒ€")
        topics[topic] = topics.get(topic, 0) + 1
    
    print("\nğŸ·ï¸ ì£¼ì œë³„ í†µê³„:")
    for topic, count in sorted(topics.items(), key=lambda x: x[1], reverse=True)[:10]:
        print(f"   {topic}: {count}ê°œ")


def cmd_read(args: argparse.Namespace):
    """ì˜ì‹ì  ì •ë…ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
    print(f"ğŸ§  ì˜ì‹ì  ì •ë…: {args.file}")
    
    # ë©”ëª¨ë¦¬ ê·¸ë˜í”„ ë¡œë“œ
    graph = PalantirGraph("memory/data/palantir_graph.json")
    
    # ì˜ì‹ì  ì½ê¸° ì‹œìŠ¤í…œ ìƒì„±
    reader = ConsciousReader(graph)
    
    # íŒŒì¼ ì½ê¸°
    with open(args.file, 'r', encoding='utf-8') as f:
        text = f.read()
    
    # ì˜ì‹ì  ì •ë… ì‹¤í–‰
    result = reader.read_consciously(text)
    
    print(f"âœ… ì •ë… ì™„ë£Œ:")
    print(f"   - ìƒí™© ê¸°ì–µ: {len(result.situational_memories)}ê°œ")
    print(f"   - ê°ì • ë³€í™”: {len(result.emotional_journey)}ê°œ")
    print(f"   - ì¸ì§€ í†µì°°: {len(result.cognitive_insights)}ê°œ")
    print(f"   - ê°œì¸ ì§„í™”: {len(result.personal_evolution)}ê°œ")
    print(f"   - ì½ê¸° í’ˆì§ˆ: {result.reading_quality:.2f}")
    
    # ë©”ëª¨ë¦¬ ì €ì¥
    graph.save()


def cmd_load(args: argparse.Namespace):
    """ê¸°ì¡´ ë©”ëª¨ë¦¬ íŒŒì¼ë“¤ì„ ë¡œë“œ"""
    print("ğŸ”„ ê¸°ì¡´ ë©”ëª¨ë¦¬ íŒŒì¼ ë¡œë“œ ì¤‘...")
    
    # ë©”ëª¨ë¦¬ ê·¸ë˜í”„ ì´ˆê¸°í™”
    graph = PalantirGraph("memory/data/palantir_graph.json")
    
    # ê¸°ì¡´ ë©”ëª¨ë¦¬ ë°ì´í„° ë¡œë“œ
    memory_files = [
        "memory/data/harin_v6_formatted_memory.jsonl",
        "memory/data/harin_v6_summary_nodes.jsonl"
    ]
    
    edge_files = [
        "memory/data/harin_v6_memory_edges.jsonl",
        "memory/data/harin_v6_summary_edges.jsonl"
    ]
    
    loaded_nodes = 0
    loaded_edges = 0
    
    for file_path in memory_files:
        if Path(file_path).exists():
            try:
                print(f"   ğŸ“„ ë¡œë“œ ì¤‘: {file_path}")
                graph.load_jsonl(file_path)
                loaded_nodes += 1
            except Exception as e:
                print(f"   âš ï¸ ê²½ê³ : {file_path} ë¡œë“œ ì‹¤íŒ¨ - {e}")
    
    for file_path in edge_files:
        if Path(file_path).exists():
            try:
                print(f"   ğŸ”— ë¡œë“œ ì¤‘: {file_path}")
                graph.load_edges(file_path)
                loaded_edges += 1
            except Exception as e:
                print(f"   âš ï¸ ê²½ê³ : {file_path} ë¡œë“œ ì‹¤íŒ¨ - {e}")
    
    # ë©”ëª¨ë¦¬ ì €ì¥
    graph.save()
    
    print(f"âœ… ë¡œë“œ ì™„ë£Œ:")
    print(f"   - ë…¸ë“œ íŒŒì¼: {loaded_nodes}ê°œ")
    print(f"   - ì—£ì§€ íŒŒì¼: {loaded_edges}ê°œ")
    print(f"   - ì´ ë…¸ë“œ: {len(graph.nodes)}ê°œ")
    print(f"   - ì´ ì—£ì§€: {len(graph.edges)}ê°œ")


def cmd_list_files(args: argparse.Namespace):
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ íŒŒì¼ ëª©ë¡"""
    print("ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ íŒŒì¼:")
    
    data_dir = Path("memory/data")
    if not data_dir.exists():
        print("   ë©”ëª¨ë¦¬ ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # JSONL íŒŒì¼ë“¤
    jsonl_files = list(data_dir.glob("*.jsonl"))
    if jsonl_files:
        print("\nğŸ“„ JSONL íŒŒì¼:")
        for file in jsonl_files:
            size = file.stat().st_size
            print(f"   {file.name} ({size:,} bytes)")
    
    # JSON íŒŒì¼ë“¤
    json_files = list(data_dir.glob("*.json"))
    if json_files:
        print("\nğŸ“‹ JSON íŒŒì¼:")
        for file in json_files:
            size = file.stat().st_size
            print(f"   {file.name} ({size:,} bytes)")
    
    # TXT íŒŒì¼ë“¤
    txt_files = list(data_dir.glob("*.txt"))
    if txt_files:
        print("\nğŸ“ TXT íŒŒì¼:")
        for file in txt_files:
            size = file.stat().st_size
            print(f"   {file.name} ({size:,} bytes)")


def build_parser() -> argparse.ArgumentParser:
    """CLI íŒŒì„œ êµ¬ì„±"""
    parser = argparse.ArgumentParser(prog="memory_cli", description="Harin ë©”ëª¨ë¦¬ ê´€ë¦¬ CLI")
    subparsers = parser.add_subparsers(dest="command", required=True)
    
    # import ëª…ë ¹
    import_parser = subparsers.add_parser("import", help="í…ìŠ¤íŠ¸ íŒŒì¼ì„ ê¸°ì–µìœ¼ë¡œ ì„í¬íŠ¸")
    import_parser.add_argument("file", help="ì„í¬íŠ¸í•  í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ")
    import_parser.add_argument("--topic", help="ì£¼ì œ íƒœê·¸")
    import_parser.set_defaults(func=cmd_import)
    
    # search ëª…ë ¹
    search_parser = subparsers.add_parser("search", help="ê¸°ì–µ ê²€ìƒ‰")
    search_parser.add_argument("query", help="ê²€ìƒ‰ ì¿¼ë¦¬")
    search_parser.set_defaults(func=cmd_search)
    
    # status ëª…ë ¹
    status_parser = subparsers.add_parser("status", help="ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸")
    status_parser.set_defaults(func=cmd_status)
    
    # read ëª…ë ¹
    read_parser = subparsers.add_parser("read", help="ì˜ì‹ì  ì •ë…ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì²˜ë¦¬")
    read_parser.add_argument("file", help="ì •ë…í•  í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ")
    read_parser.set_defaults(func=cmd_read)
    
    # load ëª…ë ¹
    load_parser = subparsers.add_parser("load", help="ê¸°ì¡´ ë©”ëª¨ë¦¬ íŒŒì¼ë“¤ì„ ë¡œë“œ")
    load_parser.set_defaults(func=cmd_load)
    
    # list ëª…ë ¹
    list_parser = subparsers.add_parser("list", help="ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ íŒŒì¼ ëª©ë¡")
    list_parser.set_defaults(func=cmd_list_files)
    
    return parser


def main(argv: List[str] | None = None):
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = build_parser()
    args = parser.parse_args(argv)
    
    if hasattr(args, "func"):
        args.func(args)
    else:
        parser.print_help(sys.stderr)


if __name__ == "__main__":
    main() 
