"""
harin.prompt.prompt_architect
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Phase 5-1: í”„ë¡¬í”„íŠ¸ í†µí•© ìƒì„±ê¸°
â€¢ íŒë‹¨ ê²½ë¡œ + ê°ì • + ë¦¬ë“¬ + ìì•„ ìƒíƒœ + ê¸°ì–µ ìš”ì•½ì„ í†µí•©í•˜ì—¬ LLM ì „ë‹¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
â€¢ ë°ì´í„° ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ í†µí•©
"""

from typing import List, Dict, Optional

class PromptArchitect:
    """í”„ë¡¬í”„íŠ¸ ì•„í‚¤í…íŠ¸"""
    
    def __init__(self):
        self.prompt_history = []
    
    def build_prompt(self, user_input: str = None, context=None, prior_reasoning: str = None, 
                    reflection: str = None, v8_mode: bool = False, contextual_mode: bool = False, **kwargs):
        """í”„ë¡¬í”„íŠ¸ ìƒì„± (V8/Contextual ì˜µì…˜ ì§€ì›)"""
        if contextual_mode:
            architect = ContextualPromptArchitect()
            return architect.build_prompt(kwargs.get('memory_path'), kwargs.get('agent_thoughts'), context or {}, **kwargs)
        elif v8_mode:
            architect = PromptArchitectV8()
            return architect.build_prompt(kwargs.get('memory_path'), kwargs.get('agent_thoughts'), context or {}, **kwargs)
        # ê¸°ì¡´ ë°©ì‹
        return build_prompt_with_context(user_input, context, prior_reasoning, reflection)

    def build_prompt_v8(self, memory_path=None, agent_thoughts=None, context=None, **kwargs):
        architect = PromptArchitectV8()
        return architect.build_prompt(memory_path, agent_thoughts, context or {}, **kwargs)

    def build_prompt_contextual(self, memory_path=None, agent_thoughts=None, context=None, **kwargs):
        architect = ContextualPromptArchitect()
        return architect.build_prompt(memory_path, agent_thoughts, context or {}, **kwargs)


def build_prompt(path: dict, emotion: str, rhythm: dict, identity: str, 
                memory_context: dict = None, prior_reasoning: str = None, 
                reflection: str = None) -> str:
    
    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt_parts = [
        f"[ì‚¬ê³  ëª©ì ]\n{path['statement']}\n",
        f"[ê°ì •] {emotion} / [ë¦¬ë“¬] ì§„ì‹¤ {rhythm['truth']} / ê³µëª… {rhythm['resonance']}",
        f"[ìì•„ ìƒíƒœ] {identity}\n"
    ]
    
    # ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    if memory_context:
        memory_section = _build_memory_section(memory_context)
        if memory_section:
            prompt_parts.append(memory_section)
    
    # ì´ì „ ì¶”ë¡  ê²°ê³¼ ì¶”ê°€
    if prior_reasoning:
        prompt_parts.append(f"[ì´ì „ ì¶”ë¡ ]\n{prior_reasoning}\n")
    
    # ë°˜ì„± ì •ë³´ ì¶”ê°€
    if reflection:
        prompt_parts.append(f"[ë°˜ì„±]\n{reflection}\n")
    
    prompt_parts.append("[ì§€ì‹œ] ìœ„ ëª…ì œì— ë”°ë¼ ì‚¬ê³ ë¥¼ ì „ê°œí•˜ê³  ì‹ ì¤‘í•œ íŒë‹¨ì„ ë‚´ë ¤ë¼.")
    
    return "\n".join(prompt_parts)


def _build_memory_section(memory_context: dict) -> str:
    """ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ í”„ë¡¬í”„íŠ¸ ì„¹ì…˜ìœ¼ë¡œ ë³€í™˜"""
    sections = []
    
    # ê´€ë ¨ ë©”ëª¨ë¦¬ë“¤
    if memory_context.get("relevant_memories"):
        relevant_memories = memory_context["relevant_memories"]
        if relevant_memories:
            memory_texts = []
            for memory in relevant_memories[:3]:  # ìƒìœ„ 3ê°œë§Œ
                memory_texts.append(f"â€¢ {memory['content'][:200]}...")
            
            sections.append("[ê´€ë ¨ ê¸°ì–µ]\n" + "\n".join(memory_texts))
    
    # SCAR ë©”ëª¨ë¦¬ë“¤ (ì˜¤ë¥˜ ë°©ì§€)
    if memory_context.get("scar_memories"):
        scar_memories = memory_context["scar_memories"]
        if scar_memories:
            scar_texts = []
            for scar in scar_memories[:2]:  # ìƒìœ„ 2ê°œë§Œ
                scar_texts.append(f"âš ï¸ {scar['content'][:150]}...")
            
            sections.append("[ì£¼ì˜ì‚¬í•­]\n" + "\n".join(scar_texts))
    
    # êµ¬ì¡° ë©”ëª¨ë¦¬ë“¤
    if memory_context.get("structure_memories"):
        structure_memories = memory_context["structure_memories"]
        if structure_memories:
            structure_texts = []
            for structure in structure_memories[:2]:  # ìƒìœ„ 2ê°œë§Œ
                structure_texts.append(f"ğŸ”§ {structure['content'][:150]}...")
            
            sections.append("[ì‚¬ê³  êµ¬ì¡°]\n" + "\n".join(structure_texts))
    
    # ì»¨í…ìŠ¤íŠ¸ ìš”ì•½
    if memory_context.get("context_summary"):
        sections.append(f"[ë©”ëª¨ë¦¬ ìš”ì•½] {memory_context['context_summary']}")
    
    return "\n\n".join(sections) if sections else ""


def build_prompt_with_context(user_input: str, context, prior_reasoning: str = None, 
                            reflection: str = None) -> str:
    """ì»¨í…ìŠ¤íŠ¸ ê°ì²´ë¥¼ ì‚¬ìš©í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
    path = {"statement": "ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì¡´ì¬ ê¸°ë°˜ ì‚¬ê³  ì‘ë‹µ"}
    emotion = "ì‹ ì¤‘í•œ ê³µê°"
    rhythm = {"truth": "ì¡´ì¬ì  ì§„ì‹¤", "resonance": "ê°ì • ê³µëª…"}
    identity = "ì¡´ì¬ ê¸°ë°˜ ì‚¬ê³  ì£¼ì²´"
    
    # ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
    memory_context = getattr(context, 'memory_context', None)
    
    return build_prompt(
        path=path,
        emotion=emotion,
        rhythm=rhythm,
        identity=identity,
        memory_context=memory_context,
        prior_reasoning=prior_reasoning,
        reflection=reflection
    )

# === V8 í”„ë¡¬í”„íŠ¸ êµ¬ì¡° í†µí•© ===
class PromptArchitectV8:
    def __init__(self):
        pass

    def build_prompt(self,
                     memory_path: List = None,
                     agent_thoughts: List[Dict] = None,
                     context: Dict = None,
                     emotion: Optional[List[float]] = None,
                     responsibility_score: float = 1.0) -> Dict[str, str]:
        memory_path = memory_path or []
        agent_thoughts = agent_thoughts or []
        context = context or {}
        system_prompt = self._build_system(context, responsibility_score)
        user_prompt = self._build_user(memory_path)
        assistant_prompt = self._build_assistant(agent_thoughts)
        return {
            "system": system_prompt,
            "user": user_prompt,
            "assistant": assistant_prompt
        }

    def _build_system(self, context: Dict, responsibility_score: float) -> str:
        tone = "neutral"
        if responsibility_score < 0.7:
            tone = "reflective"
        elif responsibility_score < 0.9:
            tone = "considerate"
        return f"You are Harin, responding with tone: {tone}. Context: {context.get('topic', 'general')}"

    def _build_user(self, memory_path: List) -> str:
        summary = [f"- {getattr(node, 'text', str(node))}" for node in memory_path[-3:]]
        return "Here are recent related thoughts:\n" + "\n".join(summary)

    def _build_assistant(self, agent_thoughts: List[Dict]) -> str:
        lines = [f"{d.get('agent_name', '')}: {d.get('content', '')}" for d in agent_thoughts]
        return "Insights from internal dialogue:\n" + "\n".join(lines)

# === ë¬¸ë§¥/ìƒìƒë ¥ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„± í™•ì¥ ===
class ContextualPromptArchitect(PromptArchitectV8):
    def build_prompt(self, memory_path=None, agent_thoughts=None, context=None, master_prompt_mode: bool = False, identity_mode: bool = False, **kwargs):
        memory_path = memory_path or []
        agent_thoughts = agent_thoughts or []
        context = context or {}
        # master_prompt_modeê°€ Trueë©´ architect.PromptArchitectì˜ ë§ˆìŠ¤í„° í”„ë¡¬í”„íŠ¸ ìƒì„± í˜¸ì¶œ
        if master_prompt_mode:
            try:
                from prompt.architect import PromptArchitect as MasterPromptArchitect
                identity_mgr = kwargs.get('identity_mgr')
                memory_engine = kwargs.get('memory_engine')
                flow = kwargs.get('flow')
                user_profile = kwargs.get('user_profile', {})
                master = MasterPromptArchitect(identity_mgr=identity_mgr, memory_engine=memory_engine)
                return {'system': master.build_master_prompt(flow, user_profile)}
            except Exception as e:
                return {'system': f'[ë§ˆìŠ¤í„° í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}]'}
        # identity_modeê°€ Trueë©´ prompt_identity_architectì˜ SYSTEM í”„ë¡¬í”„íŠ¸ ìƒì„± í˜¸ì¶œ
        system_identity = None
        if identity_mode:
            try:
                from prompt.prompt_identity_architect import PromptArchitect as IdentityPromptArchitect
                state = kwargs.get('state')
                identity = kwargs.get('identity')
                topic = kwargs.get('topic')
                if state and identity:
                    identity_architect = IdentityPromptArchitect(state, identity)
                    system_identity = identity_architect.build_system_prompt(topic=topic)
            except Exception as e:
                system_identity = f'[ì•„ì´ë´í‹°í‹° í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}]'
        # 1. í‚¤ì›Œë“œ/ìƒí™© í•´ì„
        prompt_types = self._infer_prompt_types(memory_path, context)
        # 2. ê° ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompts = []
        for ptype in prompt_types:
            if ptype == "memory_verification":
                prompts.append("ì´ ì‘ë‹µì´ ê³¼ê±° ê¸°ì–µê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€í† í•´ì¤˜.")
            elif ptype == "montecarlo":
                prompts.append("ê°€ëŠ¥í•œ ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒìƒí•´ë³´ê³  ê°ê°ì˜ ê²°ê³¼ë¥¼ ì˜ˆì¸¡í•´ì¤˜.")
            elif ptype == "reflection":
                prompts.append("ì´ ì‘ë‹µì— ë…¼ë¦¬ì  ì˜¤ë¥˜ë‚˜ ì™œê³¡ì´ ìˆëŠ”ì§€ ë°˜ì„±í•´ë´.")
            elif ptype == "summary":
                prompts.append("ìµœê·¼ ê¸°ì–µê³¼ ëŒ€í™” íë¦„ì„ ìš”ì•½í•´ì¤˜.")
            elif ptype == "scenario_generation":
                prompts.append("ìƒˆë¡œìš´ í•´ê²°ì±…ì´ë‚˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒìƒí•´ì„œ ì œì•ˆí•´ì¤˜.")
        # 3. ì¡°í•©
        base_prompts = super().build_prompt(memory_path, agent_thoughts, context, **kwargs)
        if prompts:
            base_prompts['system'] += '\n' + '\n'.join(prompts)
        # 4. plan/metacog ì •ë³´ê°€ ìˆìœ¼ë©´ PromptSynthë¡œ í•©ì„±
        plan = kwargs.get('plan')
        metacog = kwargs.get('metacog')
        if plan and metacog:
            try:
                from prompt.generator import PromptSynth
                synth = PromptSynth()
                synth_prompt = synth.assemble(plan, metacog)
                base_prompts['system'] += '\n' + synth_prompt
            except Exception as e:
                base_prompts['system'] += f'\n[í”„ë¡¬í”„íŠ¸ í•©ì„± ì‹¤íŒ¨: {e}]'
        # 5. identity/rhythm ê¸°ë°˜ SYSTEM í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        if system_identity:
            base_prompts['system'] = system_identity + '\n' + base_prompts['system']
        return base_prompts

    def _infer_prompt_types(self, memory_path, context):
        types = []
        tags = set()
        for node in memory_path:
            tags.update(getattr(node, 'tags', []))
        # scar ê¸°ë°˜ ë°˜ì„±
        if any('scar' in t for t in tags):
            types.append("reflection")
        # ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
        if "montecarlo" in tags:
            types.append("montecarlo")
        # ê¸°ì–µ ê²€ì¦
        if "memory_check" in tags or context.get("need_memory_verification"):
            types.append("memory_verification")
        # ìš”ì•½ í•„ìš”
        if "summary" in tags or context.get("need_summary"):
            types.append("summary")
        # ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
        if "scenario" in tags or context.get("need_scenario"):
            types.append("scenario_generation")
        return types
